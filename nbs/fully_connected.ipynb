{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3a877a5-65cc-47f5-9ff8-5b51fb6ae6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp nb_02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb3f861-ace5-45c8-a704-216f92850da4",
   "metadata": {},
   "source": [
    "# Impractical Deep Learning for Coders Lesson 1, The forward and backward passes (part 2)\n",
    "> Building our first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df253f74-8950-4780-b082-e2ca3c1751d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from notes.nb_01 import MNIST_URL\n",
    "from fastdownload import FastDownload\n",
    "import pickle, gzip\n",
    "from torch import tensor\n",
    "import torch, math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_data():\n",
    "    fd = FastDownload(base=\"~/.fastai\")\n",
    "    path = fd.download(MNIST_URL)\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "    return map(tensor, (x_train,y_train,x_valid,y_valid))\n",
    "\n",
    "def normalize(x, mean, std): return (x-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f76bbdbd-e09e-4f1e-9f0e-03e2e214a6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1304), tensor(0.3073))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,y_train,x_valid,y_valid = get_data()\n",
    "train_mean,train_std = x_train.mean(), x_train.std()\n",
    "train_mean,train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045bc836-cee3-4879-9a15-a08782e391cf",
   "metadata": {},
   "source": [
    "We need to normalize our data (mean ~= 0, std ~=1) by the **training** data, so they are on the same scale. If we did not then they could be considered two completely different datasets as a whole, and not actually part of the same bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37265299-11dd-484b-9a9d-76f983cc377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = normalize(x_train, train_mean, train_std)\n",
    "x_valid = normalize(x_valid, train_mean, train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53b812c5-ba3e-4e66-a693-b5bdb4504b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.1425e-08), tensor(1.))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean,train_std = x_train.mean(), x_train.std()\n",
    "train_mean,train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31bb8575-d0da-418f-b2b4-70e1cd717f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def test_near_zero(a,tol=1e-3): assert a.abs()<tol, f\"Near zero: {a}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ff2324f-a7e0-4ae9-ab74-956dc6fec113",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near_zero(x_train.mean())\n",
    "test_near_zero(1-x_train.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee765b0-0c93-4209-9688-916129ea89a0",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3223b5c5-ff48-4cb4-af10-b799fdb8d06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n,m = x_train.shape\n",
    "c = y_train.max()+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aec3b14-fee5-4d72-804a-1cb9d350cf11",
   "metadata": {},
   "source": [
    "#### Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06b98fa7-00c7-4c81-9b66-faa3fed0d0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"n\":\"Size of the training set\",\n",
    "    \"m\":\"The length of one input\",\n",
    "    \"c\":\"Number of activations eventual to classify with\"\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0209b9a2-8438-4e7b-aaba-d262502468d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, tensor(10))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n,m,c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3b836b-fad5-424b-a5a6-359daa0982a0",
   "metadata": {},
   "source": [
    "## Foundations version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4d324f-b46c-4f2c-96eb-e201da182e92",
   "metadata": {},
   "source": [
    "### Basic architecture\n",
    "\n",
    "- One hidden layer\n",
    "- Mean squared error to keep things simplified rather than cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c12a94c-ddfb-4aef-8fef-2db7f45835d7",
   "metadata": {},
   "source": [
    "We initialize with a simplified version of kaiming init / he init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1669fb-3a80-47a3-ad1d-f5cf2064ce54",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "def90af8-a3ca-4cd6-b269-f6c8e4740aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nh = 50\n",
    "w1 = torch.randn(m,nh)/math.sqrt(m)\n",
    "b1 = torch.zeros(nh)\n",
    "w2 = torch.randn(nh,1)/math.sqrt(nh)\n",
    "b2 = torch.zeros(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80329d11-2d45-4432-9b46-363b7032db59",
   "metadata": {},
   "source": [
    "#### Explaination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bd54f26-a051-438c-88e4-e2b7c85dc9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"nh\":\"The size of our fully-connected hidden layer (nodes)\",\n",
    "    \"w1\":\"One weight for our model, the first layer initialized (784,50)\",\n",
    "    \"b1\":\"The bias for that weight\",\n",
    "    \"w2\":\"Another weight for our model, the second layer (50,1)\",\n",
    "    \"b2\":\"The bias for that weight\",\n",
    "    \"torch.randn(a,b)/math.sqrt(a)\":\"Simplified kaiming init/he init\"\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b3c2fe5-f2ca-4c35-9534-5a6d104d927a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 50]), torch.Size([50]), torch.Size([50, 1]), torch.Size([1]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.shape, b1.shape, w2.shape, b2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9bcbff1f-2bd9-424a-bb7e-abbc0dcaf77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near_zero(w1.mean())\n",
    "test_near_zero(w1.std()-1/math.sqrt(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4392d74a-de8d-4e51-9a28-c15c355deb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0059), tensor(0.9924))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This should be ~ (0,1) (mean,std)\n",
    "x_valid.mean(),x_valid.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0ee1490-9ff7-4b56-98b6-c9719e4603d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin(inp, weight, bias): return inp@weight + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b58acfbd-668b-433b-9097-eadf25400a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = lin(x_valid, w1, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e4a636c-4c01-4218-b423-b64f67a0cec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1195), tensor(0.9740))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So should this because we used kaiming init which is designed to have this effect\n",
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d32d0da-27c4-4a8d-b2d0-4b047ae1f92b",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "447761b6-0668-4e8c-ae41-bb9148308c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(inp): return inp.clamp_min(0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51edd6b2-186c-428e-8749-df64952eb11b",
   "metadata": {},
   "source": [
    "#### Explaination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3612077e-86ac-4868-ad70-5241062571c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \".clamp_min\":\"A ReLU activation will turn all negatives into zero\"\n",
    "};"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cfb540-73d4-415c-ae6f-be7250dc03ae",
   "metadata": {},
   "source": [
    "> While there are other ways of writing that, if you can find a function attached to a tensor for the thing you want to do, it will almost always be faster because it will be written in C - Jeremy Howard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "041c0020-daf4-41ac-867a-3995ed2ba0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = relu(lin(x_valid, w1, b1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "abbb7f75-8cb8-488a-9511-fff8b9632a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4477), tensor(0.6152))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74256e1e-b4e0-4dac-b30b-b56484073805",
   "metadata": {},
   "source": [
    "Uh oh! What went wrong?\n",
    "\n",
    "- Whiteboard session stats at 1:31:00, [YouTube link](https://youtu.be/4u8FxNEDUeg?list=PLfYUBJiXbdtTIdtE1U8qgyxo4Jy2Y91uj&t=5473)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9790d129-f045-4172-9064-437361475810",
   "metadata": {},
   "source": [
    "Basically we took everything with a mean below zero and just got rid of it. As a result we lost a ton of good data points, and our standard deviation and mean drastically swong as a result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18022b90-6f75-4166-969a-d21a44ce03cb",
   "metadata": {},
   "source": [
    "$$s t d=\\sqrt{\\frac{2}{\\left(1+a^2\\right) \\times \\text { fan_in }}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d4961e-931f-400a-a962-86ac8706c761",
   "metadata": {},
   "source": [
    "Solution is to stick a two on the top:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "36512d65-7f79-4d67-a171-152e75e293f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "std = math.sqrt(2/m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "06720be2-150d-41fc-9aa9-b67959414f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.7099), tensor(1.1645))"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = torch.randn(m,nh)*std\n",
    "t = relu(lin(x_valid, w1,b1))\n",
    "\n",
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd87ee5-c7c1-45c3-abe6-c269d977465c",
   "metadata": {},
   "source": [
    "While this solved the standard deviation, our mean is now half because we still deleted everything below the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "d81f67f4-cf1d-491e-8aeb-026ba7332b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if...?\n",
    "def relu_v2(x): return x.clamp_min(0.) - 0.5\n",
    "def relu_v3(x): return (torch.pow(x.clamp_min(0.), 0.9)) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "440605d5-d017-4856-b55a-2bb4f0dca533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0090), tensor(0.7708))"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = torch.randn(m,nh)*std\n",
    "t = relu_v2(lin(x_valid, w1,b1))\n",
    "\n",
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "817270ed-a1b0-4fb7-b2e0-ccb6a36d1743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0069), tensor(0.7123))"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = relu_v3(lin(x_valid, w1,b1))\n",
    "\n",
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54c6ba8-fcc9-431f-b06c-5a16ac34bfe8",
   "metadata": {},
   "source": [
    "Jeremy tried seeing just what would happen if during relu we reduced it by .5, and it seems to have helped some in returning us to the correct mean:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898aea2c-9fc0-46b3-b721-ce51cf02a89b",
   "metadata": {},
   "source": [
    "How well does this work in practice? -- To test, I should try building a very basic CNN and throw it to ImageWoof and the only variance being the ReLU layer being utilized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "e7aa4e95-244e-4e1f-88b4-9bb0d824f0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import init\n",
    "w1 = torch.zeros(m,nh)\n",
    "init.kaiming_normal_(w1, mode=\"fan_out\")\n",
    "t = relu(lin(x_valid, w1, b1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "94354ab0-bde0-40e4-879a-33b34f8e4750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3.2332e-05), tensor(0.0504))"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.mean(),w1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "ea23f0be-21c9-46cb-8a83-ba7fd3078504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5996), tensor(1.1000))"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.mean(),t.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "43dcd410-3a89-4487-bba5-dc6b7cd42fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0214), tensor(0.8005))"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = torch.randn(m,nh)*math.sqrt(2./m)\n",
    "t = relu_v2(lin(x_valid, w1,b1))\n",
    "\n",
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "3ac98f94-d537-4c88-bd25-065ad840fa06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0032), tensor(0.7366))"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = relu_v3(lin(x_valid, w1,b1))\n",
    "\n",
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "9f3ad489-eb87-4fef-8cd6-a96acf620a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(xb, v2=True):\n",
    "    l1 = lin(xb, w1, b1)\n",
    "    l2 = relu_v2(l1) if v2 else relu_v3(l1)\n",
    "    l3 = lin(l2, w2, b2)\n",
    "    return l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "87c21577-5c3a-4488-b0b2-f1896a8111a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.21 ms ± 128 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=model(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "aba0ea96-7f5c-4d3f-afd6-4ac24edc8df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.23 ms ± 118 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=model(x_valid, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "164eca5f-04f3-4989-ab44-a5d32401add0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model(x_valid).shape == torch.Size([x_valid.shape[0],1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc4c5b3-f18a-4f9b-8486-0df09ce9f3e6",
   "metadata": {},
   "source": [
    "## Loss function: MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "d25add29-bb81-48fd-8599-b185e82b67b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1])"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_valid).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1798f38-0858-40a3-b693-5f8db6933f33",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "cd99539c-8799-4ba6-8a4b-3122712d6fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(output, targ): return (output.squeeze(-1) - targ).pow(2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75f24cd-f961-4be1-898f-5e3cc59fa6d4",
   "metadata": {},
   "source": [
    "#### Explaination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "1568bfaa-d861-49c6-a1e2-086014ea77ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \".squeeze()\":\"Opposite of unsqueeze, removes a dimension. We use it to remove the trailing `[1]`\"\n",
    "};"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4568573f-322e-4af0-8d7d-98130bea8b67",
   "metadata": {},
   "source": [
    "> Note: better to use -1 or 1 than just to do `squeeze()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "a9253f7f-5928-4419-ad33-d909014c8fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train,y_valid = y_train.float(),y_valid.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "7d95f760-5844-464a-a6f2-8cc69c5e4e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_a = model(x_train)\n",
    "preds_b = model(x_train,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "ca1f5067-5690-4771-9275-2fbf4b09281b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 1])"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "d396cdfd-3f38-4765-8f1f-56e3caae28a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(25.9262)"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(preds_a, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "c5961279-0fad-431e-836c-47b8978c14de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(26.0106)"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(preds_b, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948225b8-33a7-4f32-8aa7-059ed081d76a",
   "metadata": {},
   "source": [
    "## Gradients and backward pass\n",
    "\n",
    "Chain rule, chain rule, chain rule!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de0cec5-56c5-4eba-9098-b66e9b6e2c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
