{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3a877a5-65cc-47f5-9ff8-5b51fb6ae6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp nb_02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb3f861-ace5-45c8-a704-216f92850da4",
   "metadata": {},
   "source": [
    "# Lesson 1, The forward and backward passes (part 2)\n",
    "> Building our first model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2f7dd2-1441-4f02-8e72-cd9ee02f662d",
   "metadata": {},
   "source": [
    "## Initial Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df253f74-8950-4780-b082-e2ca3c1751d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from coursenotes.nb_01 import MNIST_URL\n",
    "from fastdownload import FastDownload\n",
    "import pickle, gzip\n",
    "from torch import tensor\n",
    "import torch, math\n",
    "import matplotlib.pyplot as plt\n",
    "from fastcore.test import test_close\n",
    "from torch.nn import init\n",
    "\n",
    "def get_data():\n",
    "    fd = FastDownload(base=\"~/.fastai\")\n",
    "    path = fd.download(MNIST_URL)\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "    return map(tensor, (x_train,y_train,x_valid,y_valid))\n",
    "\n",
    "def normalize(x, mean, std): return (x-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f76bbdbd-e09e-4f1e-9f0e-03e2e214a6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1304), tensor(0.3073))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,y_train,x_valid,y_valid = get_data()\n",
    "train_mean,train_std = x_train.mean(), x_train.std()\n",
    "train_mean,train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045bc836-cee3-4879-9a15-a08782e391cf",
   "metadata": {},
   "source": [
    "We need to normalize our data (mean ~= 0, std ~=1) by the **training** data, so they are on the same scale. If we did not then they could be considered two completely different datasets as a whole, and not actually part of the same bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37265299-11dd-484b-9a9d-76f983cc377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = normalize(x_train, train_mean, train_std)\n",
    "x_valid = normalize(x_valid, train_mean, train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53b812c5-ba3e-4e66-a693-b5bdb4504b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.1425e-08), tensor(1.))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean,train_std = x_train.mean(), x_train.std()\n",
    "train_mean,train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31bb8575-d0da-418f-b2b4-70e1cd717f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def test_near_zero(a,tol=1e-3): assert a.abs()<tol, f\"Near zero: {a}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ff2324f-a7e0-4ae9-ab74-956dc6fec113",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near_zero(x_train.mean())\n",
    "test_near_zero(1-x_train.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3223b5c5-ff48-4cb4-af10-b799fdb8d06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n,m = x_train.shape\n",
    "c = y_train.max()+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97716830",
   "metadata": {},
   "source": [
    "#| explain n\n",
    "Size of the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68b670e",
   "metadata": {},
   "source": [
    "#| explain m\n",
    "The length of one input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0106eebf",
   "metadata": {},
   "source": [
    "#| explain c\n",
    "Number of activations eventual to classify with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0209b9a2-8438-4e7b-aaba-d262502468d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, tensor(10))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n,m,c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3b836b-fad5-424b-a5a6-359daa0982a0",
   "metadata": {},
   "source": [
    "## Foundations version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4d324f-b46c-4f2c-96eb-e201da182e92",
   "metadata": {},
   "source": [
    "### Basic architecture\n",
    "\n",
    "- One hidden layer\n",
    "- Mean squared error to keep things simplified rather than cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c12a94c-ddfb-4aef-8fef-2db7f45835d7",
   "metadata": {},
   "source": [
    "We initialize with a simplified version of kaiming init / he init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "def90af8-a3ca-4cd6-b269-f6c8e4740aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nh = 50\n",
    "w1 = torch.randn(m,nh)/math.sqrt(m)\n",
    "b1 = torch.zeros(nh)\n",
    "w2 = torch.randn(nh,1)/math.sqrt(nh)\n",
    "b2 = torch.zeros(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6186dca",
   "metadata": {},
   "source": [
    "#| explain nh\n",
    "The size of our fully-connected hidden layer (nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1b8e3d",
   "metadata": {},
   "source": [
    "#| explain w1\n",
    "One weight for our model, the first layer initialized (784,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183d14d0",
   "metadata": {},
   "source": [
    "#| explain b1\n",
    "The bias for that weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9940c1f2",
   "metadata": {},
   "source": [
    "#| explain w2\n",
    "Another weight for our model, the second layer (50,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1f66b2",
   "metadata": {},
   "source": [
    "#| explain b2\n",
    "The bias for that weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b926ec0",
   "metadata": {},
   "source": [
    "#| explain \"torch.randn(a,b)/math.sqrt(a)\"\n",
    "Simplified kaiming init/he init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b3c2fe5-f2ca-4c35-9534-5a6d104d927a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 50]), torch.Size([50]), torch.Size([50, 1]), torch.Size([1]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.shape, b1.shape, w2.shape, b2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bcbff1f-2bd9-424a-bb7e-abbc0dcaf77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near_zero(w1.mean())\n",
    "test_near_zero(w1.std()-1/math.sqrt(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4392d74a-de8d-4e51-9a28-c15c355deb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0059), tensor(0.9924))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This should be ~ (0,1) (mean,std)\n",
    "x_valid.mean(),x_valid.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0ee1490-9ff7-4b56-98b6-c9719e4603d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin(inp, weight, bias): return inp@weight + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b58acfbd-668b-433b-9097-eadf25400a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = lin(x_valid, w1, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e4a636c-4c01-4218-b423-b64f67a0cec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0417), tensor(1.0341))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So should this because we used kaiming init which is designed to have this effect\n",
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "447761b6-0668-4e8c-ae41-bb9148308c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(inp): return inp.clamp_min(0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0e7b72",
   "metadata": {},
   "source": [
    "#| explain \".clamp_min\"\n",
    "A ReLU activation will turn all negatives into zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cfb540-73d4-415c-ae6f-be7250dc03ae",
   "metadata": {},
   "source": [
    "> While there are other ways of writing that, if you can find a function attached to a tensor for the thing you want to do, it will almost always be faster because it will be written in C - Jeremy Howard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "041c0020-daf4-41ac-867a-3995ed2ba0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = relu(lin(x_valid, w1, b1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abbb7f75-8cb8-488a-9511-fff8b9632a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.3898), tensor(0.5947))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74256e1e-b4e0-4dac-b30b-b56484073805",
   "metadata": {},
   "source": [
    "Uh oh! What went wrong?\n",
    "\n",
    "- Whiteboard session stats at 1:31:00, [YouTube link](https://youtu.be/4u8FxNEDUeg?list=PLfYUBJiXbdtTIdtE1U8qgyxo4Jy2Y91uj&t=5473)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9790d129-f045-4172-9064-437361475810",
   "metadata": {},
   "source": [
    "Basically we took everything with a mean below zero and just got rid of it. As a result we lost a ton of good data points, and our standard deviation and mean drastically swong as a result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18022b90-6f75-4166-969a-d21a44ce03cb",
   "metadata": {},
   "source": [
    "$$\\operatorname{std}=\\sqrt{\\frac{2}{\\left(1+a^2\\right) \\times \\text { fan_in }}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d4961e-931f-400a-a962-86ac8706c761",
   "metadata": {},
   "source": [
    "Solution is to stick a two on the top:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36512d65-7f79-4d67-a171-152e75e293f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "std = math.sqrt(2/m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06720be2-150d-41fc-9aa9-b67959414f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5535), tensor(0.8032))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = torch.randn(m,nh)*std\n",
    "t = relu(lin(x_valid, w1,b1))\n",
    "\n",
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd87ee5-c7c1-45c3-abe6-c269d977465c",
   "metadata": {},
   "source": [
    "While this solved the standard deviation, our mean is now half because we still deleted everything below the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d81f67f4-cf1d-491e-8aeb-026ba7332b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if...?\n",
    "def relu_v2(x): return x.clamp_min(0.) - 0.5\n",
    "def relu_v3(x): return (torch.pow(x.clamp_min(0.), 0.9)) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "440605d5-d017-4856-b55a-2bb4f0dca533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0372), tensor(0.8032))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = torch.randn(m,nh)*std\n",
    "t = relu_v2(lin(x_valid, w1,b1))\n",
    "\n",
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "817270ed-a1b0-4fb7-b2e0-ccb6a36d1743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0181), tensor(0.7405))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = relu_v3(lin(x_valid, w1,b1))\n",
    "\n",
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54c6ba8-fcc9-431f-b06c-5a16ac34bfe8",
   "metadata": {},
   "source": [
    "Jeremy tried seeing just what would happen if during relu we reduced it by .5, and it seems to have helped some in returning us to the correct mean:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898aea2c-9fc0-46b3-b721-ce51cf02a89b",
   "metadata": {},
   "source": [
    "How well does this work in practice? -- To test, I should try building a very basic CNN and throw it to ImageWoof and the only variance being the ReLU layer being utilized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7aa4e95-244e-4e1f-88b4-9bb0d824f0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = torch.zeros(m,nh)\n",
    "init.kaiming_normal_(w1, mode=\"fan_out\")\n",
    "t = relu(lin(x_valid, w1, b1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94354ab0-bde0-40e4-879a-33b34f8e4750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9.4735e-05), tensor(0.0506))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.mean(),w1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea23f0be-21c9-46cb-8a83-ba7fd3078504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4818), tensor(0.7318))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.mean(),t.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43dcd410-3a89-4487-bba5-dc6b7cd42fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0279), tensor(0.7500))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = torch.randn(m,nh)*math.sqrt(2./m)\n",
    "t = relu_v2(lin(x_valid, w1,b1))\n",
    "\n",
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ac98f94-d537-4c88-bd25-065ad840fa06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0422), tensor(0.6948))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = relu_v3(lin(x_valid, w1,b1))\n",
    "\n",
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f3ad489-eb87-4fef-8cd6-a96acf620a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(xb, v2=True):\n",
    "    l1 = lin(xb, w1, b1)\n",
    "    l2 = relu_v2(l1) if v2 else relu_v3(l1)\n",
    "    l3 = lin(l2, w2, b2)\n",
    "    return l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87c21577-5c3a-4488-b0b2-f1896a8111a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.56 ms ± 578 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=model(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aba0ea96-7f5c-4d3f-afd6-4ac24edc8df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3 ms ± 104 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=model(x_valid, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "164eca5f-04f3-4989-ab44-a5d32401add0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model(x_valid).shape == torch.Size([x_valid.shape[0],1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc4c5b3-f18a-4f9b-8486-0df09ce9f3e6",
   "metadata": {},
   "source": [
    "## Loss function: MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d25add29-bb81-48fd-8599-b185e82b67b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_valid).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd99539c-8799-4ba6-8a4b-3122712d6fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def mse(output, targ): return (output.squeeze(-1) - targ).pow(2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ea76b0",
   "metadata": {},
   "source": [
    "#| explain \".squeeze()\"\n",
    "Opposite of unsqueeze, removes a dimension. We use it to remove the trailing `[1]`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4568573f-322e-4af0-8d7d-98130bea8b67",
   "metadata": {},
   "source": [
    "> Note: better to use -1 or 1 than just to do `squeeze()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9253f7f-5928-4419-ad33-d909014c8fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train,y_valid = y_train.float(),y_valid.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d95f760-5844-464a-a6f2-8cc69c5e4e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_a = model(x_train)\n",
    "preds_b = model(x_train,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca1f5067-5690-4771-9275-2fbf4b09281b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d396cdfd-3f38-4765-8f1f-56e3caae28a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28.0614)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(preds_a, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c5961279-0fad-431e-836c-47b8978c14de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(27.8693)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(preds_b, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948225b8-33a7-4f32-8aa7-059ed081d76a",
   "metadata": {},
   "source": [
    "## Gradients and backward pass\n",
    "\n",
    "Chain rule, chain rule, chain rule!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5060107-d583-4791-a65a-b2c29f00a7f2",
   "metadata": {},
   "source": [
    "Start with our last function and go backwards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "449b6ac3-4d31-46fd-b82e-d1191c64ce7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_grad(inp, targ):\n",
    "    # grad of loss with respect to output of previous layer\n",
    "    inp.g = 2. * (inp.squeeze() - targ).unsqueeze(-1) / inp.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60188266",
   "metadata": {},
   "source": [
    "#| explain inp.g\n",
    "Gradients need to be attached to the inputs, so it can be passed across all of the functions and utilized as the output of the previous layer is the input for the current layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ce6e87",
   "metadata": {},
   "source": [
    "#| explain \"2. * (inp.squeeze() - targ).unsqueeze(-1)/ inp.shape[0]\"\n",
    "This is the derivitive of (inp-targ)^2/len(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "09da8a0c-94c2-44ec-85fe-6e72645d1c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_grad(inp, out):\n",
    "    # grad of relu with respect to input activations\n",
    "    inp.g = (inp>0).float() * out.g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e1f067",
   "metadata": {},
   "source": [
    "#| explain \"(inp>0).float() * out.g\"\n",
    "The inp>0 is familiar, but given *respect* we need to multiply it by the previous layer's gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6de4fd",
   "metadata": {},
   "source": [
    "#| explain \"inp>0\"\n",
    "Given that anything negative after a ReLU is set to 0, it has no slope and thus a derivitive of 0. We take everything above 0 as a result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef4f0563-5fa0-4446-ac21-7e0a1fb44fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_grad(inp, out, w, b):\n",
    "    # grad of matmul with respect to input\n",
    "    inp.g = out.g @ w.t() # transpose\n",
    "    w.g = (inp.unsqueeze(-1) * out.g.unsqueeze(1)).sum(0)\n",
    "    b.g = out.g.sum(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7b0a25",
   "metadata": {},
   "source": [
    "#| explain multiline out 1 t()\n",
    "The gradient of a matrix product is the product of the matrix transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffd1d6e",
   "metadata": {},
   "source": [
    "#| explain multiline w.g 0 sum\n",
    "We need the outputs with respect to the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0d536f",
   "metadata": {},
   "source": [
    "#| explain multiline \"b.g\" 0 )\n",
    "And we also need the outputs with respect to the biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9eff62eb-1d40-4681-93db-a97bf6f65127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_and_backward(inp, targ):\n",
    "    # forward pass:\n",
    "    l1 = inp @ w1 + b1\n",
    "    l2 = relu_v2(l1)\n",
    "    out = l2 @ w2 + b2\n",
    "    # We don't actually need the loss in backward\n",
    "    loss = mse(out, targ)\n",
    "    \n",
    "    # backward pass:\n",
    "    mse_grad(out, targ)\n",
    "    lin_grad(l2, out, w2, b2)\n",
    "    relu_grad(l1, l2)\n",
    "    lin_grad(inp, l1, w1, b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e9e4b8",
   "metadata": {},
   "source": [
    "#| explain \"l1 = inp @ w1 + b1\\nlin_grad(inp, l1, w1, b1)\"\n",
    "The inputs to the gradients is the original input, the output, and the rest of the options passed originally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96140ab",
   "metadata": {},
   "source": [
    "#| explain \"l2 = relu_v2(l1)\\nrelu_grad(l1, l2)\"\n",
    "This pattern continues until we start and end on the original linear layer, traveling through the model and loss function twice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024ca7be-9424-4307-b907-76a85bd0a4d4",
   "metadata": {},
   "source": [
    "Backprop *is* the chain rule, with making sure all the calculations are saved somewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "014b3cec-e313-4142-af28-3e5a134ade0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_and_backward(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "df77cc1c-02ab-4fca-9d57-30eae6bb86dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save for testing against later\n",
    "w1g = w1.g.clone()\n",
    "w2g = w2.g.clone()\n",
    "b1g = b1.g.clone()\n",
    "b2g = b2.g.clone()\n",
    "ig = x_train.g.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608ea834-72d4-45e2-8ed9-bc22cd3088c5",
   "metadata": {},
   "source": [
    "And now we cheat with pytorch `autograd` to check results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1317aea6-a736-4abb-9d68-c4c9eaeb721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt2 = x_train.clone().requires_grad_(True)\n",
    "w12 = w1.clone().requires_grad_(True)\n",
    "w22 = w2.clone().requires_grad_(True)\n",
    "b12 = b1.clone().requires_grad_(True)\n",
    "b22 = b2.clone().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e3be3dd2-9e8b-41fa-b95d-018ad0fe4a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(inp, targ):\n",
    "    # forward pass\n",
    "    l1 = inp @ w12 + b12\n",
    "    l2 = relu_v2(l1)\n",
    "    out = l2 @ w22 + b22\n",
    "    return mse(out, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a5f66759-5785-45fd-ae44-907c8599e049",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = forward(xt2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7eff037f-fec5-4736-8238-6c8cf4acf390",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6c3f2ac9-24dc-424a-ba09-3fbde40042e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now test\n",
    "test_close(w22.grad, w2g)\n",
    "test_close(b22.grad, b2g)\n",
    "test_close(w12.grad, w1g)\n",
    "test_close(b12.grad, b1g)\n",
    "test_close(xt2.grad, ig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298c7a93-fc78-4bab-bd44-e6c6ae73016e",
   "metadata": {},
   "source": [
    "## Layers as classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4820c776-affa-42e0-9062-f5ba38276f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __call__(self, inp):\n",
    "        self.inp = inp\n",
    "        self.out = inp.clamp_min(0.)-0.5\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self): \n",
    "        self.inp.g = (self.inp>0).float() * self.out.g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9213f1-c312-45fa-812a-4ec16f1e4700",
   "metadata": {},
   "source": [
    "#### Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff4e0d7",
   "metadata": {},
   "source": [
    "#| explain multiline def 0 )\n",
    "Let's the class be called with ReLU()() and perform an operation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54f5a11",
   "metadata": {},
   "source": [
    "#| explain def 1 ) \n",
    "This is our backward pass from earlier, but save it inside `self.inp.g`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "55e7b44b-bb65-4902-a311-2b37243a32ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self, w, b):\n",
    "        self.w, self.b = w, b\n",
    "    \n",
    "    def __call__(self, inp):\n",
    "        self.inp = inp\n",
    "        self.out = inp @ self.w + self.b\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self):\n",
    "        self.inp.g = self.out.g @ self.w.t()\n",
    "        # Creating a giant outer product just to sum it together is very inefficient. Do it all at once!\n",
    "        self.w.g = (self.inp.unsqueeze(-1) * self.out.g.unsqueeze(1)).sum(0)\n",
    "        self.b.g = self.out.g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0e05454a-ed12-4927-8863-0f72569887a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE():\n",
    "    def __call__(self, inp, targ):\n",
    "        self.inp = inp\n",
    "        self.targ = targ\n",
    "        self.out = (inp.squeeze() - targ).pow(2).mean()\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self):\n",
    "        self.inp.g = 2. * (self.inp.squeeze(-1) - self.targ).unsqueeze(-1) / self.targ.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c2746acb-b434-47b1-bb4e-b0458ae93297",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, w1, b1, w2, b2):\n",
    "        self.layers = [Linear(w1,b1), ReLU(), Linear(w2,b2)]\n",
    "        self.loss = MSE()\n",
    "    \n",
    "    def __call__(self, x, targ):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return self.loss(x, targ)\n",
    "    \n",
    "    def backward(self):\n",
    "        self.loss.backward()\n",
    "        for layer in reversed(self.layers):\n",
    "            layer.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f0cc012b-f611-4b8a-b058-e5d6bdc110cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset our gradients:\n",
    "w1.g, b1.g, w2.g, b2.g = [None]*4\n",
    "# And define the model\n",
    "\n",
    "model = Model(w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a0e104b5-1844-4cfd-9571-3eca8d5cfcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 77.4 ms, sys: 26.8 ms, total: 104 ms\n",
      "Wall time: 13.2 ms\n"
     ]
    }
   ],
   "source": [
    "%time loss = model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "961d1b6e-435f-481d-a8a4-e80bf6163288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.62 s, sys: 2.41 s, total: 6.03 s\n",
      "Wall time: 893 ms\n"
     ]
    }
   ],
   "source": [
    "%time model.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4fe8a115-bc71-447e-aedb-bf5aab11c15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the gradients align\n",
    "test_close(w2g, w2.g)\n",
    "test_close(b2g, b2.g)\n",
    "test_close(w1g, w1.g)\n",
    "test_close(b1g, b1.g)\n",
    "test_close(ig, x_train.g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6139ddc3-2527-439d-86cf-77be2f6b691d",
   "metadata": {},
   "source": [
    "## Refactor again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "87a2a378-7532-4d9b-8398-901e68647b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module():\n",
    "    \"Basic class that will impelement .backward() and store the args and outputs from the forward function\"\n",
    "    def __call__(self, *args):\n",
    "        self.args = args\n",
    "        self.out = self.forward(*args)\n",
    "        return self.out\n",
    "    \n",
    "    def forward(self): \n",
    "        raise NotImplementedError(\"You need to define the forward funciton still!\")\n",
    "    \n",
    "    def backward(self):\n",
    "        self.bwd(self.out, *self.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "08ed373a-a1c7-487a-80d2-41c9833f3fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(Module):\n",
    "    def forward(self, inp):\n",
    "        return inp.clamp_min(0.)-0.5\n",
    "    \n",
    "    def bwd(self, out, inp):\n",
    "        inp.g = (inp>0).float() * out.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fe742ecd-b605-40d7-a741-149d6827a777",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    def __init__(self, w, b):\n",
    "        self.w, self.b = w, b\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        return inp@self.w + self.b\n",
    "    \n",
    "    def bwd(self, out, inp):\n",
    "        inp.g = out.g @ self.w.t()\n",
    "        # Creating a giant outer product just to sum it together is very inefficient. Do it all at once!\n",
    "        self.w.g = torch.einsum(\"bi,bj->ij\",inp,out.g)\n",
    "        self.b.g = out.g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b2acf6a1-3fbb-4931-806c-20a0c6196bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE(Module):\n",
    "    def forward(self, inp, targ):\n",
    "        return (inp.squeeze() - targ).pow(2).mean()\n",
    "    \n",
    "    def bwd(self, out, inp, targ):\n",
    "        inp.g = 2. * (inp.squeeze(-1) - targ).unsqueeze(-1) / targ.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1a892c8e-c925-4ab2-a932-a34c7a3c7553",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, w1, b1, w2, b2):\n",
    "        self.layers = [Linear(w1,b1), ReLU(), Linear(w2,b2)]\n",
    "        self.loss = MSE()\n",
    "    \n",
    "    def __call__(self, x, targ):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return self.loss(x, targ)\n",
    "    \n",
    "    def backward(self):\n",
    "        self.loss.backward()\n",
    "        for layer in reversed(self.layers):\n",
    "            layer.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7f83ced2-dd47-418b-8dce-3ff6822b26ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 142 ms, sys: 0 ns, total: 142 ms\n",
      "Wall time: 19.9 ms\n"
     ]
    }
   ],
   "source": [
    "w1.g, b1.g, w2.g, b2.g = [None]*4\n",
    "model = Model(w1, b1, w2, b2)\n",
    "%time loss = model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9c04d0c2-7b85-4363-9ab7-89e13eeedce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 234 ms, sys: 157 ms, total: 391 ms\n",
      "Wall time: 49.7 ms\n"
     ]
    }
   ],
   "source": [
    "%time model.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5056a5e3-4c7d-4c47-813c-bdfae54f6fda",
   "metadata": {},
   "source": [
    "## nn.Linear and nn.Module\n",
    "\n",
    "We have now implemented both of these, and thus we're allowed to use them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "86d6d0b3-af43-4692-bb8e-a948e1017fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "abc0e956-5249-46f6-b55d-dfb211eb38cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
    "        self.loss = mse\n",
    "    \n",
    "    def __call__(self, x, targ):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return self.loss(x.squeeze(-1), targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c4a02eb0-76f6-4a07-968c-e6a4d3101f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(m, nh, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7914dae5-e522-4404-be74-e7db147c34dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 129 ms, sys: 2.81 ms, total: 131 ms\n",
      "Wall time: 19.7 ms\n"
     ]
    }
   ],
   "source": [
    "%time loss = model(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9168449f-1f52-46fe-a551-931bb9d4720b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 105 ms, sys: 0 ns, total: 105 ms\n",
      "Wall time: 16 ms\n"
     ]
    }
   ],
   "source": [
    "%time loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf09f2b-3b0b-4def-8a16-8fdae14f1d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
